# ============================================================
# Amazon Bedrock local harness config (invoke + bearer token)
# ============================================================
# Auth model:
#   - You MUST export a Bedrock long-term API key (bearer token) as an env var
#     before launching VS Code / Jupyter.
#
# Required env var:
#   export AWS_BEARER_TOKEN_BEDROCK="ABSK..."
#
# Optional env var (overrides default_region below):
#   export AWS_REGION="us-east-1"
#
# Notes:
# - Do NOT store secrets in this YAML.
# - Presets are ordered fallbacks: we try models in order until one succeeds.
# ============================================================

auth:
  token_env: "AWS_BEARER_TOKEN_BEDROCK"
  region_env: "AWS_REGION"
  default_region: "us-east-1"

http:
  timeout_seconds: 120

defaults:
  preset: "analysis_max"
  debug_fallback: true

# Base URL template for Bedrock Runtime.
endpoints:
  bedrock_runtime_base: "https://bedrock-runtime.{region}.amazonaws.com"

providers:
  anthropic:
    anthropic_version: "bedrock-2023-05-31"
  openai_compat:
    chat_completions_path: "/openai/v1/chat/completions"
    system_role: "developer"
    max_tokens_param: "max_completion_tokens"

models:
  # ---------------------------
  # Claude (Anthropic) profiles
  # ---------------------------
  # Opus 4.6 (US profile)
  claude_opus_46_us:
    provider: "anthropic"
    model_id: "us.anthropic.claude-opus-4-6-v1"

  # Opus 4.6 (Global profile)
  claude_opus_46_global:
    provider: "anthropic"
    model_id: "global.anthropic.claude-opus-4-6-v1"

  # Sonnet 4.5 (Global profile)
  claude_sonnet_45_global:
    provider: "anthropic"
    model_id: "global.anthropic.claude-sonnet-4-5-20250929-v1:0"

  # Opus 4.5 (Global profile)
  claude_opus_45_global:
    provider: "anthropic"
    model_id: "global.anthropic.claude-opus-4-5-20251101-v1:0"

  # Haiku 3.5 (US profile)
  claude_haiku_35_us:
    provider: "anthropic"
    model_id: "us.anthropic.claude-3-5-haiku-20241022-v1:0"

  # ---------------------------
  # Fallbacks (non-Claude)
  # ---------------------------
  gpt_oss_120b:
    provider: "openai_compat"
    model_id: "openai.gpt-oss-120b-1:0"

  gpt_oss_20b:
    provider: "openai_compat"
    model_id: "openai.gpt-oss-20b-1:0"

  nova_pro:
    provider: "nova"
    model_id: "amazon.nova-pro-v1:0"

  nova_micro:
    provider: "nova"
    model_id: "amazon.nova-micro-v1:0"

  # ---------------------------
  # Multimodal generation models
  # ---------------------------
  nova_canvas:
    provider: "nova"
    model_id: "amazon.nova-canvas-v1:0"

  nova_reel:
    provider: "nova"
    model_id: "amazon.nova-reel-v1:0"

presets:
  # Fast sanity checks (Claude-first)
  cheap_fast:
    - model_ref: "claude_haiku_35_us"
      temperature: 0.2
      max_output_tokens: 1024
    - model_ref: "nova_micro"
      temperature: 0.2
      max_output_tokens: 1024
    - model_ref: "gpt_oss_20b"
      temperature: 0.2
      max_output_tokens: 1024

  # Strong default
  analysis_default:
    - model_ref: "claude_sonnet_45_global"
      temperature: 0.2
      max_output_tokens: 3072
    - model_ref: "claude_opus_45_global"
      temperature: 0.2
      max_output_tokens: 3072
    - model_ref: "gpt_oss_120b"
      temperature: 0.2
      max_output_tokens: 3072
    - model_ref: "nova_pro"
      temperature: 0.2
      max_output_tokens: 3072

  # High quality (no extended thinking)
  analysis_high:
    - model_ref: "claude_opus_46_us"
      temperature: 0.2
      max_output_tokens: 4096
    - model_ref: "claude_sonnet_45_global"
      temperature: 0.2
      max_output_tokens: 4096
    - model_ref: "gpt_oss_120b"
      temperature: 0.2
      max_output_tokens: 4096
    - model_ref: "nova_pro"
      temperature: 0.2
      max_output_tokens: 4096

  # Max reasoning (extended thinking on Claude; Claude-first with explicit fallbacks)
  analysis_max:
    - model_ref: "claude_opus_46_global"
      # IMPORTANT: when thinking is enabled, Claude requires temperature=1
      temperature: 1
      max_output_tokens: 16000
      anthropic:
        thinking:
          enabled: true
          budget_tokens: 14000

    - model_ref: "gpt_oss_120b"
      temperature: 0.2
      max_output_tokens: 8192

    - model_ref: "nova_pro"
      temperature: 0.2
      max_output_tokens: 8192

multimodal:
  output_dir: "./outputs"

  # Scenarios executed by default in test_bedrock_multimodal.ipynb
  default_run:
    - "image_generation_canvas"
    - "video_generation_reel"
    - "image_understanding_claude"
    - "video_understanding_claude"

  scenarios:
    # ---------------------------------------------------------
    # 1) Image generation (Nova Canvas)
    # ---------------------------------------------------------
    image_generation_canvas:
      kind: "invoke_template"
      model_ref: "nova_canvas"
      endpoint_path: "/model/{model_id}/invoke"
      timeout_seconds: 180

      template_vars:
        prompt: "A cinematic cyberpunk city at sunrise, volumetric light, ultra detailed."
        negative_prompt: "blurry, low resolution, watermark, text artifacts"
        width: 1024
        height: 1024
        cfg_scale: 8.0
        seed: 7
        number_of_images: 1

      request_template:
        taskType: "TEXT_IMAGE"
        textToImageParams:
          text: "{prompt}"
          negativeText: "{negative_prompt}"
        imageGenerationConfig:
          numberOfImages: "{number_of_images}"
          width: "{width}"
          height: "{height}"
          cfgScale: "{cfg_scale}"
          seed: "{seed}"

      response:
        type: "base64_images"
        path: "images"
        save_dir: "images"
        file_ext: "png"

    # ---------------------------------------------------------
    # 2) Video generation (Nova Reel)
    #    If your account/region returns async job metadata only,
    #    the notebook will capture the job id for follow-up polling.
    # ---------------------------------------------------------
    video_generation_reel:
      kind: "invoke_template"
      model_ref: "nova_reel"
      endpoint_path: "/model/{model_id}/invoke"
      timeout_seconds: 300

      template_vars:
        prompt: "A drone fly-through above snow mountains at golden hour, cinematic."
        duration_seconds: 6
        fps: 24
        dimension: "1280x720"
        seed: 11

      request_template:
        taskType: "TEXT_VIDEO"
        textToVideoParams:
          text: "{prompt}"
        videoGenerationConfig:
          durationSeconds: "{duration_seconds}"
          fps: "{fps}"
          dimension: "{dimension}"
          seed: "{seed}"

      response:
        type: "base64_video_or_job"
        video_path_candidates:
          - "video"
          - "videoBase64"
          - "output.video"
          - "result.video"
        job_id_candidates:
          - "invocationArn"
          - "jobArn"
          - "jobId"
          - "id"
        save_dir: "videos"
        file_ext: "mp4"

    # ---------------------------------------------------------
    # 3) Image understanding (Claude multimodal)
    # ---------------------------------------------------------
    image_understanding_claude:
      kind: "anthropic_messages"
      model_ref: "claude_sonnet_45_global"
      timeout_seconds: 180
      max_output_tokens: 1200
      temperature: 0.2

      system_prompt: "You are a visual analyst. Be precise and concise."
      user_prompt: "Please describe the image, extract key objects, and infer the likely scenario."
      media:
        - name: "input_image"
          type: "image"
          path: "./samples/demo_image.jpg"
          media_type: "image/jpeg"

      response:
        type: "anthropic_text"

    # ---------------------------------------------------------
    # 4) Video understanding (Claude multimodal)
    # ---------------------------------------------------------
    video_understanding_claude:
      kind: "anthropic_messages"
      model_ref: "claude_sonnet_45_global"
      timeout_seconds: 240
      max_output_tokens: 1400
      temperature: 0.2

      system_prompt: "You are a video analyst. Summarize actions, timeline, and key events."
      user_prompt: "Please summarize this video and list major events in chronological order."
      media:
        - name: "input_video"
          type: "video"
          path: "./samples/demo_video.mp4"
          media_type: "video/mp4"

      response:
        type: "anthropic_text"
